{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN/M3nqC/qJRuX/0pSJeuaw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamilPiatkowski1997/Traffic_signs/blob/main/Traffic_signs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download german traffic signs dataset for model training\n",
        "!git clone https://bitbucket.org/jadslim/german-traffic-signs"
      ],
      "metadata": {
        "id": "7ihxRXUYrl56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "V7VMeRSVrov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opening pickle files and creating variables for testing, training and validation data\n",
        "with open('german-traffic-signs/train.p','rb') as f:    #rb means read binary format.\n",
        "    train_data = pickle.load(f)                                    #f is pointer\n",
        "with open('german-traffic-signs/test.p','rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "with open('german-traffic-signs/valid.p','rb') as f:\n",
        "    valid_data = pickle.load(f)\n",
        "\n",
        "print(type(train_data))\n",
        "\n",
        "X_train, y_train = train_data['features'], train_data['labels']\n",
        "X_val, y_val = valid_data['features'], valid_data['labels']\n",
        "X_test, y_test = test_data['features'], test_data['labels']\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "assert(X_train.shape[0] == y_train.shape[0]), 'The number of images is not equal to the number of labels'\n",
        "assert(X_val.shape[0] == y_val.shape[0]), 'The number of images is not equal to the number of labels'\n",
        "assert(X_test.shape[0] == y_test.shape[0]), 'The number of images is not equal to the number of labels'\n",
        "\n",
        "assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32x32x3\"\n",
        "assert(X_val.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32x32x3\"\n",
        "assert(X_test.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32x32x3\"\n",
        "\n",
        "data = pd.read_csv('german-traffic-signs/signnames.csv')\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "sM-wK9bKrp1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1000\n",
        "\n",
        "label = y_train[idx]\n",
        "sign_name = data.loc[label, \"SignName\"]\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray\")\n",
        "#plt.title(f\"{label} - {sign_name}\")\n",
        "#plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7P-mUqnS3zM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display 3 random images for each label class. If throwing error run all again.\n",
        "num_of_samples = []\n",
        "list_signs = []\n",
        "cols = 3\n",
        "num_classes = 43\n",
        "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,50))\n",
        "fig.tight_layout()\n",
        "\n",
        "for i in range(cols):\n",
        "    for j, row in data.iterrows():\n",
        "        x_selected = X_train[y_train == j]\n",
        "        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected - 1)), :, :], cmap = plt.get_cmap(\"gray\"))\n",
        "        axs[j][i].axis(\"off\")\n",
        "        if i == 2:\n",
        "            axs[j][i].set_title(str(j) + \"-\" + row[\"SignName\"])\n",
        "            list_signs.append(row[\"SignName\"])\n",
        "            num_of_samples.append(len(x_selected))"
      ],
      "metadata": {
        "id": "Yz48GOF9ruts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display dataset distribiution\n",
        "print(num_of_samples)\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.bar(range(0, num_classes), num_of_samples)\n",
        "plt.title(\"Distribiution of the training dataset\")\n",
        "plt.xlabel(\"Class number\")\n",
        "plt.ylabel(\"Number of images\")"
      ],
      "metadata": {
        "id": "qIZRtNw9rv1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting image into gray scale so that neural network can learn the pattern easily\n",
        "def gray(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "\n",
        "def equalize(img):\n",
        "    img = cv2.equalizeHist(img)\n",
        "    return img\n",
        "  #equalize histogram extract reigon of interest very correctly\n",
        "\n",
        "def preprocess(img):\n",
        "    img = gray(img)\n",
        "    img = equalize(img)\n",
        "    img = img/255 #normalizing of images\n",
        "    return img"
      ],
      "metadata": {
        "id": "N-v6Mx3IrxGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Map preprocessed images\n",
        "X_train = np.array(list(map(preprocess, X_train)))\n",
        "X_val = np.array(list(map(preprocess, X_val)))\n",
        "X_test = np.array(list(map(preprocess, X_test)))"
      ],
      "metadata": {
        "id": "giblPxnYrySD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape mapped and preprocessed images\n",
        "X_train = X_train.reshape(34799, 32, 32, 1)\n",
        "X_test = X_test.reshape(12630, 32, 32, 1)\n",
        "X_val = X_val.reshape(4410, 32, 32, 1)\n",
        "\n",
        "img_rows, img_cols, channels = 32, 32, 1\n",
        "\n",
        "#Display dataset shape\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "bP-CHRIcr1Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Manipulate data within the batches for better model recognition\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            zoom_range=0.2,\n",
        "                            shear_range=0.1,\n",
        "                            rotation_range=10.)\n",
        "datagen.fit(X_train)\n",
        "# for X_batch, y_batch in\n",
        "\n",
        "batches = datagen.flow(X_train, y_train, batch_size = 15)\n",
        "X_batch, y_batch = next(batches)\n",
        "\n",
        "fig, axs = plt.subplots(1, 15, figsize=(20, 5))\n",
        "fig.tight_layout()\n",
        "\n",
        "#Display batch of random 15 images\n",
        "for i in range(15):\n",
        "    axs[i].imshow(X_batch[i].reshape(32, 32))\n",
        "    axs[i].axis(\"off\")\n",
        "\n",
        "print(X_batch.shape)"
      ],
      "metadata": {
        "id": "LDpGtWbGr2MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorise the images\n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)\n",
        "y_val = to_categorical(y_val, 43)"
      ],
      "metadata": {
        "id": "G37i99-zr3bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the 4 layers model for sign prediction\n",
        "def modified_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(60,(5,5),input_shape=(32,32,1),activation='relu'))\n",
        "    model.add(Conv2D(60,(5,5),activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "    model.add(Conv2D(30,(3,3),activation='relu'))\n",
        "    model.add(Conv2D(30,(3,3),activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#     model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500,activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(num_classes ,activation='softmax'))\n",
        "    #Compile model\n",
        "    model.compile(Adam(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "9rLeHkf9r4s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display model parameters\n",
        "model = modified_model()\n",
        "defence_model = modified_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "PcVLOGEIr6AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train model\n",
        "steps = int(X_train.shape[0] / 50)\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=50),\n",
        "    steps_per_epoch = steps,\n",
        "    epochs = 10,\n",
        "    validation_data = (X_val, y_val),\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "# history = model.fit(datagen.flow(X_train,y_train, batch_size=50), steps_per_epoch = X_train.shape[0]/50, epochs = 10, validation_data= (X_val, y_val), shuffle = 1)\n",
        "# history = model.fit(X_train, y_train, epochs = 10, validation_data = (X_val, y_val), batch_size = 400, verbose = 1, shuffle = 1)"
      ],
      "metadata": {
        "id": "qwkMlWjAr7K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display Loss agains epoch graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')"
      ],
      "metadata": {
        "id": "bFKHNxXFsOi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display accuracy agains epoch graph\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epoch')"
      ],
      "metadata": {
        "id": "igWgq1R7sQe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print model score and accuracy\n",
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print(type(score))\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "_M_9IBcSsRtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch image\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "url = 'https://c8.alamy.com/comp/G667W0/road-sign-speed-limit-30-kmh-zone-passau-bavaria-germany-G667W0.jpg'\n",
        "# url = 'https://c8.alamy.com/comp/A0RX23/cars-and-automobiles-must-turn-left-ahead-sign-A0RX23.jpg'\n",
        "# url = 'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg'\n",
        "# url = 'https://previews.123rf.com/images/pejo/pejo0907/pejo090700003/5155701-german-traffic-sign-no-205-give-way.jpg'\n",
        "# url = 'https://kids.kiddle.co/images/thumb/f/f9/STOP_sign.jpg/300px-STOP_sign.jpg'\n",
        "# url = 'https://s3.eu-west-1.amazonaws.com/cdn.webfactore.co.uk/sr_279629_large.jpg'\n",
        "\n",
        "#Preprocess image from url\n",
        "r = requests.get(url, stream=True)\n",
        "img = Image.open(r.raw)\n",
        "plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "img = np.asarray(img)\n",
        "img = cv2.resize(img, (32, 32))\n",
        "img = preprocess(img)\n",
        "img = img.reshape(1, 32, 32, 1)\n",
        "\n",
        "#Test image\n",
        "prediction=np.argmax(model.predict(img), axis=-1)\n",
        "print((prediction[0], (list_signs[prediction[0]])))"
      ],
      "metadata": {
        "id": "o4zZ4z1_sTPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create adversarial pattern\n",
        "def adversarial_pattern(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = tf.keras.losses.MSE(label, prediction)\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    return signed_grad"
      ],
      "metadata": {
        "id": "naJvILgt5JeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a signle example of 20km/h before and after creating adversarial pattern\n",
        "image = X_train[1000]\n",
        "image_label = y_train[10000]\n",
        "perturbations = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), image_label).numpy()\n",
        "adversarial = image + perturbations * 0.1\n",
        "\n",
        "print(\"Model prediction == \",list_signs[model.predict(image.reshape((1, img_rows, img_cols, channels))).argmax()])\n",
        "print(\"Prediction with Intrusion== \", list_signs[model.predict(adversarial).argmax()])\n",
        "\n",
        "if channels == 1:\n",
        "    plt.imshow(adversarial.reshape((img_rows, img_cols)))\n",
        "else:\n",
        "    plt.imshow(adversarial.reshape((img_rows, img_cols, channels)))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0X5WeVrg5NxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}